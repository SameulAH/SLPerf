## 大致过程
和FedSplit一样, 有两个服务端, FedServer和SplitServer, SplitServer就是正常学习用的, 而FedServer 则用来聚合模型

只不过FedServer聚合模型的时候不是发送global_model 而是发送随机的几个其他客户端的模型

之后每个客户端都使用fomo优化来给最适合自己的几个模型赋予较高的权重, 然后再在本地聚合(默认所有客户端都是能参与训练的)

## 具体过程

1. 各个客户端正常和splitServer学习, 这里从采用同时进行学习的方式. (当然也可以考虑采用轮流的方式)

2. 各个客户端将自己本地模型上传给fedServer, fedServer有一个概率权重矩阵, p\[i]\[j]表示把第j个客户端的模型发送给第i个客户端的概率权重. 按照这个概率给每个客户端发送M个模型

3. 现在每个客户端有M个模型, 于是使用本地验证集判断哪个模型更优, 具体做法如下:

   1. 对于每个模型直接跑本地验证集, 不用splitServer返回梯度, 只需要返回loss就行
   
   2. 然后再根据fomo公式算出权值w, 不允许负值, 然后把所有的w归一化
   
4. 用w聚合这些模型, 注意w可能全为0, 此时相当于不聚合模型.

5. 聚合完的客户端模型开始下一轮学习, 即回到1


## 优势

1. split 和 fed 的优势: 比如即使客户端资源有限也能学习等

2. 两个server都不知道完整的模型, 隐私保护程度高

3. 之前观察到, 正常SL的时候, 在non-IID设置下, 客户端对训练集的正确率都很高, 说明SplitServer的模型对不同的label都能学习到, 也不会互相干扰, 在测试集的准确率低的原因是**client的模型没学到其他label的数据的特征**

   于是如果加入fedfomo这种算法, 让每个client学到更全面, 更优的模型, 理论上就能提高最终准确率
   

## 问题

1. 如果大家的目标都一样